{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5a94671",
      "metadata": {
        "id": "c5a94671"
      },
      "source": [
        "# \n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=cc57b01f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f2d714",
      "metadata": {
        "id": "a1f2d714"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from ddpm import LatentDiffusionModel, CustomDataset, get_ddpm_scheduler_variables, extract\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "timesteps = 1000\n",
        "timesteps, betas, alphas, alphas_cumprod, alphas_cumprod_prev, sqrt_recip_alphas, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod, posterior_variance = get_ddpm_scheduler_variables(timesteps=timesteps)\n",
        "\n",
        "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "\n",
        "# 初始化模型\n",
        "latent_dim = 256\n",
        "hidden_dims = [2048, 2048, 2048, 2048] \n",
        "# hidden_dims = [1024, 1024, 1024, 1024] \n",
        "max_freq = 4  # Example max frequency for Fourier features\n",
        "num_bands = 4  # Number of frequency bands\n",
        "scalar_hidden_dims = [256,256,256,256]\n",
        "diffusion_model = LatentDiffusionModel(latent_dim, hidden_dims, scalar_hidden_dims, max_freq, num_bands).to(device)\n",
        "# diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/mugs_ddpm_cos_20k_test1/model.pth\"\n",
        "# diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/mugs_ddpm_cos_20k_l2loss/model.pth\"\n",
        "# diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/mugs_ddpm_cos_30k_l1huber_normT/model.pth\"\n",
        "# diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/mugs_ddpm_cos_30k_l2_normT/model.pth\"\n",
        "# diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/NEWmugs_ddpm_cos_10k_l1huber/model.pth\"\n",
        "# diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/mugs_ddpm_cos_30k_l1huber_normT_1024/model.pth\"\n",
        "# diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/mugs_ddpm_cos_100k_l1huber_normT_2048_steps10k/model.pth\"\n",
        "\n",
        "# 12-31\n",
        "diffusion_ckpt_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/mugs_ddpm_cos_200k_l1huber_normT_2048_dataNorm/model_epo199999.pth\"\n",
        "diffusion_ckpt = torch.load(diffusion_ckpt_path)\n",
        "diffusion_model.load_state_dict(diffusion_ckpt['model'])\n",
        "diffusion_model = diffusion_model.to(device)\n",
        "print('Diffusion Model parameters:', sum(p.numel() for p in diffusion_model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef5a44bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "time_value = 999\n",
        "t = torch.tensor([time_value]*3)\n",
        "tensor = torch.tensor([10]*3)\n",
        "extract(posterior_variance, t, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a83fefc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "sqrt_alphas_cumprod[0:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf4bac1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_x_0_list = []\n",
        "@torch.no_grad()\n",
        "def uncond_p_sample(model, x, t, t_index):\n",
        "    betas_t = extract(betas, t, x.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
        "    \n",
        "    # Equation 11 in the paper\n",
        "    # Use our model (noise predictor) to predict the mean\n",
        "    # Note: \\grad_{x_t} \\log p(x_t|x_0) = - (\\epsilon) / (\\sqrt{1 - \\alpha^{hat}_t})\n",
        "    #                                   = - model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
        "    model_out = model(x, t, timesteps)\n",
        "\n",
        "    score_x = model_out / sqrt_one_minus_alphas_cumprod_t\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        x - betas_t * score_x\n",
        "    )\n",
        "    # if t[0]>1:\n",
        "    #     sqrt_alphas_cumprod_tminus1 = extract(sqrt_alphas_cumprod, t-1, x.shape)\n",
        "    # else:\n",
        "    #     sqrt_alphas_cumprod_tminus1 = torch.ones_like(x)\n",
        "    # pred_x_0 = sqrt_recip_alphas_t * (x - sqrt_one_minus_alphas_cumprod_t * model_out) / sqrt_alphas_cumprod_tminus1\n",
        "    \n",
        "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x.shape)\n",
        "    pred_x_0 = (x - sqrt_one_minus_alphas_cumprod_t * model_out) / sqrt_alphas_cumprod_t\n",
        "    pred_x_0_list.append(pred_x_0)\n",
        "    \n",
        "    if t_index == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
        "        noise = torch.randn_like(x)\n",
        "        # Algorithm 2 line 4:\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
        "        \n",
        "# Algorithm 2:\n",
        "@torch.no_grad()\n",
        "def uncond_p_sample_loop(model, shape, return_traj = False):\n",
        "    # assert eta in [0, 1]\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    b = shape[0]\n",
        "    # start from pure noise (for each example in the batch)\n",
        "    x_t = torch.randn(shape, device=device)\n",
        "    traj = []\n",
        "\n",
        "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
        "        x_t_minus1 = uncond_p_sample(model, x_t, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
        "        x_t = x_t_minus1\n",
        "        traj.append(x_t.cpu().numpy())\n",
        "    if return_traj:\n",
        "        return traj\n",
        "    else:    \n",
        "        return x_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2111920c",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(12)\n",
        "bs = 5\n",
        "eta = 1.\n",
        "trajs = uncond_p_sample_loop(model=diffusion_model, shape=(bs, 256, 4), return_traj=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0073c7a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from init import get_AEmodel_cfg\n",
        "from core.models import get_model\n",
        "category = \"mugs\"\n",
        "# category = \"kit4cates\"\n",
        "# category = \"chairs\"\n",
        "config_Only_model = get_AEmodel_cfg()\n",
        "ModelClass = get_model(config_Only_model[\"model\"][\"model_name\"])\n",
        "model = ModelClass(config_Only_model)\n",
        "ckpt_path = f\"/home/ziran/se3/EFEM/weights/{category}.pt\"\n",
        "# ckpt_path = f\"/home/ziran/se3/EFEM/lib_shape_prior/log/12_10_shape_prior_mugs_old/12_10_shape_prior_mugs_FOR_hopefullybetterAE/checkpoint/15409.pt\"\n",
        "ckpt = torch.load(ckpt_path)\n",
        "model.network.load_state_dict(ckpt['model_state_dict'])\n",
        "model.network = model.network.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "493b1538",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(pred_x_0_list)\n",
        "\n",
        "# pred_x_0_list[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7129f972",
      "metadata": {},
      "outputs": [],
      "source": [
        "codebook_path = f\"/home/ziran/se3/EFEM/cache/mugs.npz\"\n",
        "train_ds = CustomDataset(codebook_path, normalization = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea7115c",
      "metadata": {},
      "source": [
        "## Traj over time(predicted x_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff3a78b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "time_slice = slice(1, 1001, 50)\n",
        "print(time_slice)\n",
        "sample_idx = 2\n",
        "a = torch.stack([item[sample_idx] for item in pred_x_0_list[time_slice]], dim=0)\n",
        "a.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd765d2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from viz_x import viz_x, viz_x_img\n",
        "\n",
        "# viz_x(a, model, device)\n",
        "single_images, combined_image = viz_x_img(a, model, device, train_ds.normal_params)\n",
        "from IPython.display import display\n",
        "display(combined_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc9d562e",
      "metadata": {},
      "source": [
        "## Traj over time (x_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd24a8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "time_slice = slice(990, 1001, 1)\n",
        "sample_idx = 0\n",
        "\n",
        "latent_x = np.stack(trajs[time_slice])[:,sample_idx,...]\n",
        "latent_x = torch.from_numpy(latent_x)\n",
        "latent_x.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1762d40b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from viz_x import viz_x\n",
        "viz_x(latent_x, model, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8812e2a8",
      "metadata": {},
      "source": [
        "## simple viz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5317cae0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from viz_x import viz_x\n",
        "# viz_x(latent_x, model, device)\n",
        "\n",
        "viz_x(torch.tensor(trajs[-1]), model, device, train_ds.normal_params)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6fe49a34",
        "2d747688",
        "5153024b",
        "592aa765",
        "9ff47fbb",
        "51d9a24c",
        "9a8031b0",
        "06b3fad0",
        "a30368b2",
        "cc01c63b",
        "f70235f8",
        "b02eb802"
      ],
      "name": "annotated-diffusion.ipynb",
      "provenance": []
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
