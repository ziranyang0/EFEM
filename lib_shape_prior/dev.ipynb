{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:27 | Set GPU: 0 ...   [post_config.py:99]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:27 | Save configuration to local file...   [post_config.py:105]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:27 | Dataset train with 100.0% data, dataset len is 149, total len is 149   [shapenet_new2.py:203]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:27 | Caching train dataset...   [shapenet_new2.py:231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Please check the configuration\n",
      "--------------------------------------------------------------------------------\n",
      "{'dataset': {'aug_ratio': 0.7,\n",
      "             'categories': ['03797390'],\n",
      "             'data_root': '../data/ShapeNetV1_SDF',\n",
      "             'dataset_name': 'shapenet_new2',\n",
      "             'dataset_proportion': [1.0, 1.0],\n",
      "             'dataset_root': 'resource/data/XXXX',\n",
      "             'dep_max_use_view': 12,\n",
      "             'dep_min_use_view': 4,\n",
      "             'dep_total_view': 12,\n",
      "             'depth_postfix': '_dep_small',\n",
      "             'field_mode': 'sdf',\n",
      "             'indices': {'test_index': 'None',\n",
      "                         'train_index': 'None',\n",
      "                         'val_index': 'None'},\n",
      "             'input_mode': 'dep',\n",
      "             'n_pcl': 512,\n",
      "             'n_query_eval': 10000,\n",
      "             'n_query_nss': 1024,\n",
      "             'n_query_uni': 1024,\n",
      "             'noise_std': 0.01,\n",
      "             'num_workers': 8,\n",
      "             'pin_mem': True,\n",
      "             'ram_cache': True,\n",
      "             'random_ball_removal_max_k': 25,\n",
      "             'random_ball_removal_noise_std': 0.05,\n",
      "             'random_ball_removal_prob': 0.7,\n",
      "             'random_object_center_L': 0.1,\n",
      "             'random_object_center_near_surface': True,\n",
      "             'random_object_prob': 0.7,\n",
      "             'random_object_radius': 0.15,\n",
      "             'random_object_radius_std': 0.09,\n",
      "             'random_object_scale': [0.5, 2.0],\n",
      "             'random_plane_ground_range': 0.2,\n",
      "             'random_plane_ground_scale': [0.4, 1.0],\n",
      "             'random_plane_prob': 0.0,\n",
      "             'random_plane_vertical_height_range': [0.4, 1.0],\n",
      "             'random_plane_vertical_horizon_range': [0.0, 0.5],\n",
      "             'random_plane_vertical_prob': 0.0,\n",
      "             'random_plane_vertical_scale': [0.05, 0.5],\n",
      "             'shapenet_split_fn': './splits/all.csv',\n",
      "             'use_augmentation': True,\n",
      "             'use_dataset': True},\n",
      " 'enable_anomaly': False,\n",
      " 'evaluation': {'batch_size': 4,\n",
      "                'eval_every_epoch': 1,\n",
      "                'eval_every_iter': 1000,\n",
      "                'iou_threshold': 0.5},\n",
      " 'generation': {'occ_if_meshing_cfg': {'batch_pts': 8000,\n",
      "                                       'refinement_step': 0,\n",
      "                                       'resolution_0': 32,\n",
      "                                       'simplify_nfaces': 5000,\n",
      "                                       'threshold': 0.5,\n",
      "                                       'upsampling_steps': 2,\n",
      "                                       'use_sampling': False}},\n",
      " 'gpu': '0',\n",
      " 'logging': {'backup_files': ['run.py'],\n",
      "             'checkpoint_epoch': 100,\n",
      "             'checkpoint_iter': 1000,\n",
      "             'debug_mode': False,\n",
      "             'log_dir': 'shape_prior_mugs',\n",
      "             'loggers': ['mesh',\n",
      "                         'image',\n",
      "                         'hist',\n",
      "                         'video',\n",
      "                         'xls',\n",
      "                         'checkpoint',\n",
      "                         'metric'],\n",
      "             'model_select_larger': True,\n",
      "             'model_select_metric': 'iou',\n",
      "             'viz_epoch_interval': 1,\n",
      "             'viz_iter_interval': 1000,\n",
      "             'viz_nontrain_batch_interval': 5,\n",
      "             'viz_nontrain_interval': 1,\n",
      "             'viz_one_per_batch': True,\n",
      "             'viz_training_batch_interval': 30},\n",
      " 'method': 'sim3vec-mugs',\n",
      " 'model': {'center_aug_std': 0.05,\n",
      "           'decoder': {'hidden_size': 256,\n",
      "                       'input_dim': 513,\n",
      "                       'leaky': False,\n",
      "                       'legacy': False},\n",
      "           'decoder_type': 'inner',\n",
      "           'encoder': {'atten_multi_head_c': 16,\n",
      "                       'atten_start_layer': 100,\n",
      "                       'c_dim': 256,\n",
      "                       'center_pred': True,\n",
      "                       'down_sample_factor': [2, 4, 4],\n",
      "                       'down_sample_layers': [2, 4, 5],\n",
      "                       'feat_dim': [32, 32, 64, 64, 128, 256, 512],\n",
      "                       'leak_neg_slope': 0.2,\n",
      "                       'num_knn': 16,\n",
      "                       'num_layers': 7,\n",
      "                       'res_global_start_layer': 2,\n",
      "                       'scale_factor': 64000.0,\n",
      "                       'use_dg': True,\n",
      "                       'use_res_global_conv': True},\n",
      "           'encoder_64': False,\n",
      "           'encoder_type': 'vecdgcnn_atten',\n",
      "           'loss_far_lambda': 0.5,\n",
      "           'loss_near_lambda': 1.0,\n",
      "           'loss_th': 0.1,\n",
      "           'model_name': 'sim3sdf_vanilla',\n",
      "           'sdf2occ_factor': -1.0,\n",
      "           'w_nss': 0.5,\n",
      "           'w_recon': 1.0,\n",
      "           'w_s': 0.001,\n",
      "           'w_t': 0.2,\n",
      "           'w_uni': 0.5},\n",
      " 'modes': ['train', 'val'],\n",
      " 'rand_seed': 12345,\n",
      " 'resume': 'None',\n",
      " 'root': '/home/ziran/se3/EFEM/lib_shape_prior',\n",
      " 'runner': 'solver_v2',\n",
      " 'training': {'batch_size': 32,\n",
      "              'clear_phase_cache': False,\n",
      "              'grad_clip': 4.0,\n",
      "              'initialize_network_file': [],\n",
      "              'initialize_network_name': [],\n",
      "              'loss_clip': 4.0,\n",
      "              'optim': {'all': {'decay_factor': [0.3, 0.3, 0.3],\n",
      "                                'decay_schedule': [50000, 60000, 70000],\n",
      "                                'lr': 0.0001,\n",
      "                                'lr_min': 1e-08}},\n",
      "              'total_epoch': 10,\n",
      "              'total_iter': 80000}}\n",
      "--------------------------------------------------------------------------------\n",
      "y/n?y Warning, NO INTERACTIVE CONFIRM!\n",
      "================================================================================\n",
      "Warning! No resume but log dir: /home/ziran/se3/EFEM/lib_shape_prior/log/shape_prior_mugs exists. Remove the old dir? y/n\n",
      "y Warning, NO INTERACTIVE CONFIRMATION, RENAME OLD LOG DIR!\n",
      "Log dir confirmed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [00:03<00:00, 37.33it/s]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:31 | Dataset val with 100.0% data, dataset len is 22, total len is 22   [shapenet_new2.py:203]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:31 | Caching val dataset...   [shapenet_new2.py:231]\n",
      "100%|██████████| 22/22 [00:00<00:00, 37.03it/s]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:32 | DGCNN use Dynamic Graph (different from the input topology)   [vec_dgcnn_atten.py:50]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:32 | 2.016M params in encoder   [misc.py:16]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | INFO | Nov-30-15:13:32 | 0.790M params in decoder   [misc.py:16]\n",
      "| sim3vec-mugs | user-AS-4124GS-TNR | WARNING | Nov-30-15:13:32 | Network Components != Optimizer Config   [model_base.py:31]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from dataset import get_dataset\n",
    "from logger import Logger\n",
    "from core.models import get_model\n",
    "from core import solver_dict\n",
    "from init import get_cfg, setup_seed, dev_get_cfg\n",
    "\n",
    "# preparer configuration\n",
    "cfg  =dev_get_cfg()\n",
    "\n",
    "device = \"cuda:3\"\n",
    "\n",
    "# set random seed\n",
    "setup_seed(cfg[\"rand_seed\"])\n",
    "\n",
    "# prepare dataset\n",
    "DatasetClass = get_dataset(cfg)\n",
    "datasets_dict = dict()\n",
    "for mode in cfg[\"modes\"]:\n",
    "    datasets_dict[mode] = DatasetClass(cfg, mode=mode)\n",
    "\n",
    "# prepare models\n",
    "ModelClass = get_model(cfg[\"model\"][\"model_name\"])\n",
    "model = ModelClass(cfg)\n",
    "\n",
    "# prepare logger\n",
    "logger = Logger(cfg)\n",
    "\n",
    "# register dataset, models, logger to the solver\n",
    "solver = solver_dict[cfg[\"runner\"].lower()](cfg, model, datasets_dict, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = \"/home/ziran/se3/EFEM/weights/mugs.pt\"\n",
    "ckpt = torch.load(ckpt_path)\n",
    "model.network.load_state_dict(ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_so3 (149, 256, 3)\n",
      "z_inv (149, 256)\n",
      "center (149, 1, 3)\n",
      "scale (149,)\n",
      "z_so3_proj (149, 256, 3)\n",
      "z_so3_basis (149, 3, 3)\n",
      "z_so3_var (149, 3)\n",
      "bbox (149, 3)\n",
      "bbox_c (149, 3)\n",
      "pcl (149, 5000, 3)\n",
      "cls (149,)\n"
     ]
    }
   ],
   "source": [
    "# codebook_path = \"/home/ziran/se3/EFEM/lib_shape_prior/dev_ckpt/codebook.npz\"\n",
    "codebook_path = \"/home/ziran/se3/EFEM/cache/mugs.npz\"\n",
    "\n",
    "with np.load(codebook_path) as data:\n",
    "    # 将 npz 文件内容转换为字典\n",
    "    codebook = {key: data[key] for key in data}\n",
    "\n",
    "del codebook['id']\n",
    "for k, v in codebook.items():\n",
    "    if isinstance(v, np.ndarray):\n",
    "        newv = torch.from_numpy(v)\n",
    "        codebook[k] = newv\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['z_so3', 'z_inv', 'center', 'scale', 'z_so3_proj', 'z_so3_basis', 'z_so3_var', 'bbox', 'bbox_c', 'pcl', 'cls'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7090)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codebook['scale'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m pred_center \u001b[38;5;241m=\u001b[39m codebook[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m][:bs]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# pred_center = torch.zeros_like(pred_center)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 上面两个注释掉的, 如果用默认0和1的center和scale, 会导致decode不太行, 还是用codebook里的比较好\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 于是那就应该把这四个variable一块diffusion\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m pred_so3_feat \u001b[38;5;241m=\u001b[39m \u001b[43mpred_so3_feat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m pred_inv_feat \u001b[38;5;241m=\u001b[39m pred_inv_feat\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m pred_scale \u001b[38;5;241m=\u001b[39m pred_scale\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "bs = 1\n",
    "pred_so3_feat = codebook['z_so3'][:bs]\n",
    "pred_inv_feat = codebook['z_inv'][:bs]\n",
    "pred_scale = codebook['scale'][:bs]\n",
    "# pred_scale = torch.ones_like(pred_scale) + 0.2\n",
    "pred_center = codebook['center'][:bs]\n",
    "# pred_center = torch.zeros_like(pred_center)\n",
    "# 上面两个注释掉的, 如果用默认0和1的center和scale, 会导致decode不太行, 还是用codebook里的比较好\n",
    "# 于是那就应该把这四个variable一块diffusion\n",
    "pred_so3_feat = pred_so3_feat.to(device)\n",
    "pred_inv_feat = pred_inv_feat.to(device)\n",
    "pred_scale = pred_scale.to(device)\n",
    "pred_center = pred_center.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 64\n",
    "\n",
    "space_dim = [N, N, N]  # 示例为一个50x50x50的网格\n",
    "\n",
    "\n",
    "di = 1\n",
    "# 创建一个网格，这里我们使用np.linspace来产生线性间隔的点\n",
    "x = np.linspace(-di, di, space_dim[0])\n",
    "y = np.linspace(-di, di, space_dim[1])\n",
    "z = np.linspace(-di, di, space_dim[2])\n",
    "\n",
    "# 用np.meshgrid得到每个维度的点阵\n",
    "X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "# 将这些点整理成query的形式，每行是一个点的坐标\n",
    "query = np.stack([X.ravel(), Y.ravel(), Z.ravel()], axis=-1)\n",
    "query = torch.tensor(query,dtype=torch.float32).to(device)\n",
    "query = query.repeat(bs, 1, 1)\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {\n",
    "            \"z_so3\": pred_so3_feat, # [B, 256, 3]\n",
    "            \"z_inv\": pred_inv_feat, # [B, 256]\n",
    "            \"s\": pred_scale, # [B]\n",
    "            # \"t\": centroid.unsqueeze(1), # [B, 1, 3]\n",
    "            \"t\": pred_center, # [B, 1, 3]\n",
    "        }\n",
    "\n",
    "sdf_hat = model.network.decode(  # SDF must have nss sampling\n",
    "            query,\n",
    "            None,\n",
    "            embedding,\n",
    "            return_sdf=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_grid = sdf_hat.reshape(-1, space_dim[0], space_dim[1], space_dim[2]).to(\"cpu\").detach().numpy()\n",
    "data = sdf_grid[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "# 使用 Marching Cubes 算法提取等值面\n",
    "verts, faces, normals, values = measure.marching_cubes(data, level=0.)\n",
    "\n",
    "# 创建一个新的图形\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 绘制等值面\n",
    "ax.plot_trisurf(verts[:, 0], verts[:,1], faces, verts[:, 2],\n",
    "                cmap='Spectral', lw=1)\n",
    "\n",
    "# 设置图形的视角和轴标签\n",
    "ax.view_init(30, 60)\n",
    "ax.set_xlabel(\"X-axis\")\n",
    "ax.set_ylabel(\"Y-axis\")\n",
    "ax.set_zlabel(\"Z-axis\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
